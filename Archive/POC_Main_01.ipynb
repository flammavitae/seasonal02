{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flammavitae/seasonal01/blob/main/POC_Main_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MXXypq-KeDUW"
      },
      "outputs": [],
      "source": [
        "# prompt: from a given list of stock symbols, if CSV files exist load them. Otherwise, download closing prices for the last 20 years and save the prices as CSV files. For the loaded prices, combine into a single dataframe and remove dates where prices do not exist for all symbols. calculate percentage the differences in prices from one day to the next and create a separate dataframe for the logs of the differences. Calculate sharpe ratio, standard deviations, maximum drawdown and profit for each symbol. Calculate efficient frontier and optimum portfolio with maximum sharpe.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import os\n",
        "from datetime import date, timedelta\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Globals\n",
        "data_dir = 'Data'\n",
        "\n",
        "\n",
        "def download_and_process_stock_data(stock_symbols, start_date='2004-01-01', end_date=date.today().strftime('%Y-%m-%d')):\n",
        "    \"\"\"\n",
        "    Downloads or loads stock data, calculates daily returns, logs of returns, Sharpe ratio, etc.\n",
        "    \"\"\"\n",
        "    # Create a directory for storing CSV files\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    all_data = []\n",
        "    short_symbols = []\n",
        "    for symbol in stock_symbols:\n",
        "        csv_file = f'{data_dir}/{symbol}.csv'\n",
        "\n",
        "        if os.path.exists(csv_file):\n",
        "            print(f\"Loading data from CSV: {symbol}.csv\")\n",
        "            try:\n",
        "              data = pd.read_csv(csv_file, index_col='Date', parse_dates=True)\n",
        "            except pd.errors.EmptyDataError:\n",
        "              print(f\"Error: {symbol}.csv is empty. Downloading...\")\n",
        "              data = yf.download(symbol, start=start_date, end=end_date)\n",
        "              data.to_csv(csv_file)\n",
        "            except pd.errors.ParserError:\n",
        "              print(f\"Error: {symbol}.csv parsing error. Downloading...\")\n",
        "              data = yf.download(symbol, start=start_date, end=end_date)\n",
        "              data.to_csv(csv_file)\n",
        "        else:\n",
        "            print(f\"Downloading data for {symbol}...\")\n",
        "            data = yf.download(symbol, start=start_date, end=end_date)\n",
        "            data.to_csv(csv_file)\n",
        "\n",
        "        all_data.append(data['Close'])\n",
        "        short_symbols.append('short_' + symbol)\n",
        "\n",
        "    # Combine data into a single dataframe\n",
        "    combined_data = pd.concat(all_data, axis=1)\n",
        "\n",
        "    # Short\n",
        "    all_data = all_data * -1\n",
        "    combined_data = pd.concat(all_data, axis=1)\n",
        "    stock_symbols = stock_symbols.append(short_symbols)\n",
        "    combined_data.columns = stock_symbols\n",
        "    print(combined_data)\n",
        "\n",
        "    # Remove dates with missing values\n",
        "    combined_data = combined_data.dropna()\n",
        "\n",
        "    # Calculate daily percentage change\n",
        "    daily_returns = combined_data.pct_change().dropna()\n",
        "\n",
        "    # Calculate logs of daily returns\n",
        "    log_returns = np.log(1+daily_returns)\n",
        "\n",
        "    # ... Rest of the code as before ...\n",
        "\n",
        "    # Calculate Sharpe ratio, std dev, max drawdown, etc.\n",
        "    results = {}\n",
        "    for symbol in stock_symbols:\n",
        "      results[symbol] = calculate_metrics(combined_data[symbol])\n",
        "\n",
        "    # Efficient Frontier and Optimal portfolio (Illustrative example, may need to be modified based on your needs)\n",
        "    # Example: assuming risk-free rate is 0.02\n",
        "    risk_free_rate = 0.02\n",
        "    calculate_efficient_frontier(daily_returns, risk_free_rate)\n",
        "\n",
        "    return combined_data, daily_returns, log_returns, results\n",
        "\n",
        "\n",
        "def calculate_metrics(price_series):\n",
        "  \"\"\"\n",
        "  Calculate metrics like Sharpe ratio, standard deviation, max drawdown, and profit.\n",
        "  \"\"\"\n",
        "  daily_returns = price_series.pct_change().dropna()\n",
        "  sharpe = (daily_returns.mean() - 0.02) / daily_returns.std() * np.sqrt(252)  # Annualized Sharpe ratio\n",
        "  std_dev = daily_returns.std() * np.sqrt(252)  # Annualized std dev\n",
        "  max_drawdown = calculate_max_drawdown(price_series)\n",
        "  profit = (price_series[-1] - price_series[0]) / price_series[0]  # total profit\n",
        "\n",
        "  return {\"Sharpe Ratio\": sharpe, \"Standard Deviation\": std_dev, \"Max Drawdown\": max_drawdown, \"Total Profit\": profit}\n",
        "\n",
        "def calculate_max_drawdown(price_series):\n",
        "  # Find the peak and trough for each drawdown\n",
        "  peak = price_series.expanding(min_periods=1).max()\n",
        "  drawdown = (price_series - peak) / peak\n",
        "  max_drawdown = drawdown.min()\n",
        "  return max_drawdown\n",
        "\n",
        "def calculate_efficient_frontier(returns, risk_free_rate):\n",
        "  # Illustrative Example - replace this with your own efficient frontier calculation method\n",
        "  print(\"Calculating efficient frontier (example implementation)...\")\n",
        "  # ... code to calculate efficient frontier ...\n",
        "  print(\"Efficient Frontier Calculated.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "uOCbaBvShqdG",
        "outputId": "d5d552bf-286a-482f-c133-29342e73c3ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from CSV: AAPL.csv\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "'Date' is not in list",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m stock_symbols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOG\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m combined_data, daily_returns, log_returns, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_process_stock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_symbols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCombined Stock Data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, combined_data\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDaily Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, daily_returns\u001b[38;5;241m.\u001b[39mhead())\n",
            "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mdownload_and_process_stock_data\u001b[1;34m(stock_symbols, start_date, end_date)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data from CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m   data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pd\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mEmptyDataError:\n\u001b[0;32m     32\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv is empty. Downloading...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:162\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_parse_dates_presence(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_noconvert_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:215\u001b[0m, in \u001b[0;36mCParserWrapper._set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m col_indices \u001b[38;5;241m=\u001b[39m [names_dict[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames]  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m noconvert_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_noconvert_dtype_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[has-type]\u001b[39;49;00m\n\u001b[0;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m noconvert_columns:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mset_noconvert(col)\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:664\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns\u001b[1;34m(self, col_indices, names)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col:\n\u001b[1;32m--> 664\u001b[0m         noconvert_columns\u001b[38;5;241m.\u001b[39madd(\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     noconvert_columns\u001b[38;5;241m.\u001b[39madd(_set(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col))\n",
            "File \u001b[1;32mh:\\Program Files\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:641\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns.<locals>._set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m     x \u001b[38;5;241m=\u001b[39m usecols[x]\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(x):\n\u001b[1;32m--> 641\u001b[0m     x \u001b[38;5;241m=\u001b[39m col_indices[\u001b[43mnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[1;31mValueError\u001b[0m: 'Date' is not in list"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "stock_symbols = ['AAPL', 'MSFT', 'GOOG']\n",
        "combined_data, daily_returns, log_returns, metrics = download_and_process_stock_data(stock_symbols)\n",
        "\n",
        "print(\"\\nCombined Stock Data:\\n\", combined_data.head())\n",
        "print(\"\\nDaily Returns:\\n\", daily_returns.head())\n",
        "print(\"\\nLog of Daily Returns:\\n\", log_returns.head())\n",
        "print(\"\\nMetrics\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elDJRpv7zjNB",
        "outputId": "8fa683ce-6ad2-46df-867e-5eba98dd8bed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from CSV: AAPL.csv\n",
            "Loading data from CSV: MSFT.csv\n",
            "Loading data from CSV: GOOG.csv\n",
            "['short_AAPL', 'short_MSFT', 'short_GOOG']\n",
            "RangeIndex(start=0, stop=0, step=1)\n",
            "                  AAPL        MSFT        GOOG\n",
            "Date                                          \n",
            "2004-01-02    0.320548   17.041073         NaN\n",
            "2004-01-05    0.333954   17.469440         NaN\n",
            "2004-01-06    0.332749   17.531515         NaN\n",
            "2004-01-07    0.340281   17.512890         NaN\n",
            "2004-01-08    0.351880   17.481848         NaN\n",
            "...                ...         ...         ...\n",
            "2025-01-17  229.979996  429.029999  197.550003\n",
            "2025-01-21  222.639999  428.500000  199.630005\n",
            "2025-01-22  223.830002  446.200012  200.029999\n",
            "2025-01-23  223.660004  446.709991  199.580002\n",
            "2025-01-24  222.779999  444.059998  201.899994\n",
            "\n",
            "[5300 rows x 3 columns]\n",
            "                  AAPL        MSFT        GOOG\n",
            "Date                                          \n",
            "2004-08-19    0.462595   16.836203    2.490185\n",
            "2004-08-20    0.463951   16.885881    2.687981\n",
            "2004-08-23    0.468169   16.960588    2.715032\n",
            "2004-08-24    0.481274   16.960588    2.602608\n",
            "2004-08-25    0.497844   17.153606    2.630652\n",
            "...                ...         ...         ...\n",
            "2025-01-17  229.979996  429.029999  197.550003\n",
            "2025-01-21  222.639999  428.500000  199.630005\n",
            "2025-01-22  223.830002  446.200012  200.029999\n",
            "2025-01-23  223.660004  446.709991  199.580002\n",
            "2025-01-24  222.779999  444.059998  201.899994\n",
            "\n",
            "[5142 rows x 3 columns]\n",
            "Calculating efficient frontier (example implementation)...\n",
            "Efficient Frontier Calculated.\n",
            "\n",
            "Combined Stock Data:\n",
            "                 AAPL       MSFT      GOOG\n",
            "Date                                     \n",
            "2004-08-19  0.462595  16.836203  2.490185\n",
            "2004-08-20  0.463951  16.885881  2.687981\n",
            "2004-08-23  0.468169  16.960588  2.715032\n",
            "2004-08-24  0.481274  16.960588  2.602608\n",
            "2004-08-25  0.497844  17.153606  2.630652\n",
            "\n",
            "Daily Returns:\n",
            "                 AAPL      MSFT      GOOG\n",
            "Date                                    \n",
            "2004-08-20  0.002930  0.002951  0.079430\n",
            "2004-08-23  0.009091  0.004424  0.010064\n",
            "2004-08-24  0.027993  0.000000 -0.041408\n",
            "2004-08-25  0.034429  0.011380  0.010775\n",
            "2004-08-26  0.048714 -0.003993  0.018019\n",
            "\n",
            "Log of Daily Returns:\n",
            "                 AAPL      MSFT      GOOG\n",
            "Date                                    \n",
            "2004-08-20  0.002926  0.002946  0.076433\n",
            "2004-08-23  0.009050  0.004414  0.010013\n",
            "2004-08-24  0.027608  0.000000 -0.042289\n",
            "2004-08-25  0.033850  0.011316  0.010717\n",
            "2004-08-26  0.047565 -0.004001  0.017859\n",
            "\n",
            "Metrics {'AAPL': {'Sharpe Ratio': -14.475574885071833, 'Standard Deviation': 0.32362799467652026, 'Max Drawdown': -0.6086675047717656, 'Total Profit': 480.5871434106385}, 'MSFT': {'Sharpe Ratio': -17.984979708645778, 'Standard Deviation': 0.269299738803586, 'Max Drawdown': -0.5794195405339323, 'Total Profit': 25.375306091444916}, 'GOOG': {'Sharpe Ratio': -15.626770366261365, 'Standard Deviation': 0.3057603543609379, 'Max Drawdown': -0.652947630919076, 'Total Profit': 80.07829475436817}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-81-c30e4d28274c>:106: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  profit = (price_series[-1] - price_series[0]) / price_series[0]  # total profit\n"
          ]
        }
      ],
      "source": [
        "# prompt: based on the contenbt file AAPL.csv, rewrite the reading of the csv to return only the closing price data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import os\n",
        "from datetime import date, timedelta\n",
        "\n",
        "\n",
        "def download_and_process_stock_data(stock_symbols, start_date='2004-01-01', end_date=date.today().strftime('%Y-%m-%d')):\n",
        "    \"\"\"\n",
        "    Downloads or loads stock data, calculates daily returns, logs of returns, Sharpe ratio, etc.\n",
        "    \"\"\"\n",
        "    # Create a directory for storing CSV files\n",
        "    if not os.path.exists('stock_data'):\n",
        "        os.makedirs('stock_data')\n",
        "\n",
        "    all_data = []\n",
        "    short_symbols = []\n",
        "    for symbol in stock_symbols:\n",
        "        csv_file = f'stock_data/{symbol}.csv'\n",
        "\n",
        "        if os.path.exists(csv_file):\n",
        "            print(f\"Loading data from CSV: {symbol}.csv\")\n",
        "            try:\n",
        "              # Read only the 'Close' column\n",
        "              data = pd.read_csv(csv_file)\n",
        "              # Remove the ticker row (assuming it's the first row)\n",
        "              # No information was provided about the ticker row, so it will be assumed that the first row is the ticker row.\n",
        "              data = data.iloc[2:]\n",
        "\n",
        "              # Rename the 'Price' column to 'Date'\n",
        "              data = data.rename(columns={'Price': 'Date'})\n",
        "              #data = data[['Date', 'Close']]\n",
        "              data['Close'] = np.float64(data['Close'])\n",
        "\n",
        "              # Convert 'Date' column to datetime objects\n",
        "              data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "              # Set 'Date' as the index\n",
        "              data = data.set_index('Date')\n",
        "\n",
        "            except pd.errors.EmptyDataError:\n",
        "              print(f\"Error: {symbol}.csv is empty. Downloading...\")\n",
        "              data = yf.download(symbol, start=start_date, end=end_date)\n",
        "              data.to_csv(csv_file)\n",
        "            except pd.errors.ParserError:\n",
        "              print(f\"Error: {symbol}.csv parsing error. Downloading...\")\n",
        "              data = yf.download(symbol, start=start_date, end=end_date)\n",
        "              data.to_csv(csv_file)\n",
        "        else:\n",
        "            print(f\"Downloading data for {symbol}...\")\n",
        "            data = yf.download(symbol, start=start_date, end=end_date)\n",
        "            data.to_csv(csv_file)\n",
        "        short_symbols.append('short_' + symbol)\n",
        "\n",
        "        all_data.append(data['Close'])\n",
        "\n",
        "    # Combine data into a single dataframe\n",
        "    combined_data = pd.concat(all_data, axis=1)\n",
        "    combined_data.columns = stock_symbols\n",
        "\n",
        "    # # Short\n",
        "    short_data = pd.DataFrame(all_data * -1)\n",
        "    print(short_symbols)\n",
        "    #short_data.columns = short_symbols\n",
        "    print(short_data.columns)\n",
        "    combined_data = pd.concat([combined_data, short_data], axis=1)\n",
        "    #combined_data = combined_data.join(short_data)\n",
        "\n",
        "    print(combined_data)\n",
        "\n",
        "    # Remove dates with missing values\n",
        "    combined_data = combined_data.dropna()\n",
        "    print(combined_data)\n",
        "    # Calculate daily percentage change\n",
        "    daily_returns = combined_data.pct_change(1).dropna()\n",
        "\n",
        "    # Calculate logs of daily returns\n",
        "    log_returns = np.log(1+daily_returns)\n",
        "\n",
        "    # ... Rest of the code as before ...\n",
        "\n",
        "    # Calculate Sharpe ratio, std dev, max drawdown, etc.\n",
        "    results = {}\n",
        "    for symbol in stock_symbols:\n",
        "      results[symbol] = calculate_metrics(combined_data[symbol])\n",
        "\n",
        "    # Efficient Frontier and Optimal portfolio (Illustrative example, may need to be modified based on your needs)\n",
        "    # Example: assuming risk-free rate is 0.02\n",
        "    risk_free_rate = 0.02\n",
        "    calculate_efficient_frontier(daily_returns, risk_free_rate)\n",
        "\n",
        "    return combined_data, daily_returns, log_returns, results\n",
        "    #return combined_data\n",
        "\n",
        "\n",
        "def calculate_metrics(price_series):\n",
        "  \"\"\"\n",
        "  Calculate metrics like Sharpe ratio, standard deviation, max drawdown, and profit.\n",
        "  \"\"\"\n",
        "  daily_returns = price_series.pct_change().dropna()\n",
        "  sharpe = (daily_returns.mean() - 0.02) / daily_returns.std() * np.sqrt(252)  # Annualized Sharpe ratio\n",
        "  std_dev = daily_returns.std() * np.sqrt(252)  # Annualized std dev\n",
        "  max_drawdown = calculate_max_drawdown(price_series)\n",
        "  profit = (price_series[-1] - price_series[0]) / price_series[0]  # total profit\n",
        "\n",
        "  return {\"Sharpe Ratio\": sharpe, \"Standard Deviation\": std_dev, \"Max Drawdown\": max_drawdown, \"Total Profit\": profit}\n",
        "\n",
        "def calculate_max_drawdown(price_series):\n",
        "  # Find the peak and trough for each drawdown\n",
        "  peak = price_series.expanding(min_periods=1).max()\n",
        "  drawdown = (price_series - peak) / peak\n",
        "  max_drawdown = drawdown.min()\n",
        "  return max_drawdown\n",
        "\n",
        "def calculate_efficient_frontier(returns, risk_free_rate):\n",
        "  # Illustrative Example - replace this with your own efficient frontier calculation method\n",
        "  print(\"Calculating efficient frontier (example implementation)...\")\n",
        "  # ... code to calculate efficient frontier ...\n",
        "  print(\"Efficient Frontier Calculated.\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "stock_symbols = ['AAPL', 'MSFT', 'GOOG']\n",
        "combined_data, daily_returns, log_returns, metrics = download_and_process_stock_data(stock_symbols)\n",
        "#combined_data = download_and_process_stock_data(stock_symbols)\n",
        "\n",
        "print(\"\\nCombined Stock Data:\\n\", combined_data.head())\n",
        "print(\"\\nDaily Returns:\\n\", daily_returns.head())\n",
        "print(\"\\nLog of Daily Returns:\\n\", log_returns.head())\n",
        "print(\"\\nMetrics\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "X1hBvnPc0G3W",
        "outputId": "a95f5725-50fb-4a2d-ad0d-e31e440719ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  AAPL        MSFT        GOOG\n",
            "Date                                          \n",
            "2004-08-19   -0.462595  -16.836203   -2.490185\n",
            "2004-08-20   -0.463951  -16.885881   -2.687981\n",
            "2004-08-23   -0.468169  -16.960588   -2.715032\n",
            "2004-08-24   -0.481274  -16.960588   -2.602608\n",
            "2004-08-25   -0.497844  -17.153606   -2.630652\n",
            "...                ...         ...         ...\n",
            "2025-01-17 -229.979996 -429.029999 -197.550003\n",
            "2025-01-21 -222.639999 -428.500000 -199.630005\n",
            "2025-01-22 -223.830002 -446.200012 -200.029999\n",
            "2025-01-23 -223.660004 -446.709991 -199.580002\n",
            "2025-01-24 -222.779999 -444.059998 -201.899994\n",
            "\n",
            "[5142 rows x 3 columns]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-361aea5631a3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshort_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_data\u001b[0m  \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcombined_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#stock_symbols = stock_symbols.append(short_symbols)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    417\u001b[0m     ) -> None:\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    420\u001b[0m                 \u001b[0;34m\"first argument must be an iterable of pandas \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0;34mf'objects, you passed an object of type \"{type(objs).__name__}\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
          ]
        }
      ],
      "source": [
        "# Short\n",
        "short_data = combined_data  * -1\n",
        "print(short_data)\n",
        "combined_data = pd.concat(short_data, axis=1)\n",
        "#stock_symbols = stock_symbols.append(short_symbols)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "SdBauDdqCX8d"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"B\": [0, 6, 2, 5, np.nan, 4]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "8LbhdsNGIdf0",
        "outputId": "1a524fcd-9954-4e2a-ab8f-dbcdb4750dd5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32446537223219646,\n        \"min\": 2.6666666666666665,\n        \"max\": 3.4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.6666666666666665,\n          3.25,\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-55f3e3f7-f720-43a2-b8dd-ab57ef26aa45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55f3e3f7-f720-43a2-b8dd-ab57ef26aa45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55f3e3f7-f720-43a2-b8dd-ab57ef26aa45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55f3e3f7-f720-43a2-b8dd-ab57ef26aa45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d5ef8d0f-cbbc-420c-a3ad-1769a6fa281b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5ef8d0f-cbbc-420c-a3ad-1769a6fa281b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d5ef8d0f-cbbc-420c-a3ad-1769a6fa281b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          B\n",
              "0       NaN\n",
              "1       NaN\n",
              "2  2.666667\n",
              "3  3.250000\n",
              "4  3.250000\n",
              "5  3.400000"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.expanding(3).mean()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNCKtKBD0L0y94g3VbYTBq0",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
